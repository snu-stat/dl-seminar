---
layout: post
title:  "Schedule"
date:   2016-03-16 13:05:48 +0900
categories: schedule
---
## Short Introduction

* Part I will cover a [draft](http://www.deeplearningbook.org/)(version 2016-03-08) from Bengio group, along with related papers.  Organized by Seyoon Ko and Prof. Joong-Ho Won
* Part II will cover various topics and examples of convolutional network. Organized by [Yongchan Kwon](https://ykwon0407.github.io) and Prof. Myunghee Cho Paik

## Timeslot

* Part I: 12:00p-3:00p every Friday for six weeks. Each session is 1.5 hrs long unless otherwise noted
* Part II: 3:00p-5:00p every other Friday. Each session is 1 hr long unless otherwise noted


## Schedule

### 2016-03-18

* Part II
    - Short introduction (Data driven, Online course, Future plan) : 권용찬
    - Convolutional Neural Network (Convolution layer, Pooling layer) : 김영근

### 2016-03-25
* 장소: 25-210
* Part I, Day One Special (4.5 hr)
    * §6. Deep Feedforward Networks : 최영원
    * §7. Regularization for Deep Learning : 고세윤
    * §9. Convolutional Networks : 전정민

### 2016-04-01

* Part I 
    * §10. Sequence Modeling: Recurrent and Recursive Nets: 김용준
* __Part I and II Joint Talk__ (2hr, 1:30p~)
    * §8. Optimization for Training Deep Models: 최영근
        * With more emphasis on :
            * [Stochastic gradient descent](https://github.com/cs231n/cs231n.github.io/blob/master/neural-networks-3.md#sgd)
            * Momentum methods, including [Nesterov's momentum](http://arxiv.org/pdf/1212.0901v2.pdf)
            * Adaptive learning rates, including [Adagrad](http://jmlr.org/papers/v12/duchi11a.html), [Adadelta](http://arxiv.org/abs/1212.5701), [RMSProp](http://www.cs.toronto.edu/~tijmen/csc321/slides/lecture_slides_lec6.pdf), [ADAM](http://arxiv.org/abs/1412.6980) 

### 2016-04-08 

* Part I, 4 hr special
    * §11. Practical Methodology: (1hr)
    * §12. Applications
    * §13-14. Linear Factor Models and Autoencoders

### 2016-04-15

* Part I
    * §15. Representation Learning
    * §16. Structured Probabilistic Models for Deep Learning
* Part II
    - Layer 1 (ReLU, [Dropout](https://www.cs.toronto.edu/~hinton/absps/JMLRdropout.pdf), [Maxout](http://jmlr.csail.mit.edu/proceedings/papers/v28/goodfellow13.pdf), [Batch Normalization](http://arxiv.org/abs/1502.03167)) : 김지수
    - Layer 2 ([Random initialization](http://jmlr.org/proceedings/papers/v9/glorot10a/glorot10a.pdf), [other ref.](http://arxiv.org/abs/1502.01852)) + [Check Neural Networks](https://github.com/cs231n/cs231n.github.io/blob/master/neural-networks-3.md#baby) : 고세윤

### 2016-04-22
* Part I, Double Jeopardy (each session is 1 hr long)
    * §17. Monte Carlo Methods
    * §18. Confronting the Partition Function: 고세윤
    * §19. Approximate Inference

### 2016-04-29
* Part I
    * §20. Deep Generative Models (Part 1): Boltzmann Machines
    * §20. Deep Generative Models (Part 2): Other Generative Models
* Part II
    - Deep software practice (Caffe, Keras, ..) : 최영원
    - [AlexNet](http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf) : 권용찬
 
### 2016-05-13
* Part II
    - [ZFNet](http://arxiv.org/abs/1311.2901) : 고세윤
    - [VGGNet](http://www.robots.ox.ac.uk/~vgg/research/very_deep/) : 김지수
 
### 2016-05-27

* Part II
    - [GoogLeNet](http://arxiv.org/abs/1409.4842) : 최영근
    - [ResNet](http://arxiv.org/abs/1512.03385) : 김영근

Check it out! [Google Groups](https://groups.google.com/forum/#!forum/deep-reading-club)


